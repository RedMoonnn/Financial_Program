# 金融数据采集平台 dflow 重构指南

## 1. 什么是 dflow

### 1.1 dflow 核心理念

**dflow** 是一个基于 Python 的科学计算工作流框架，其核心思想是：

> **将复杂任务拆解为可复用的原子操作（OP），通过 DAG（有向无环图）定义依赖关系，由调度引擎自动编排执行。**

```
┌─────────────────────────────────────────────────────────────────┐
│                        dflow 核心概念                            │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   ┌─────────┐                                                   │
│   │   OP    │  原子操作单元，定义输入→处理→输出                   │
│   └────┬────┘                                                   │
│        │                                                        │
│        ▼                                                        │
│   ┌─────────┐                                                   │
│   │  Step   │  OP的实例化，可配置参数、资源、重试策略             │
│   └────┬────┘                                                   │
│        │                                                        │
│        ▼                                                        │
│   ┌─────────┐                                                   │
│   │Workflow │  由多个Step组成的DAG，定义执行顺序和依赖           │
│   └────┬────┘                                                   │
│        │                                                        │
│        ▼                                                        │
│   ┌─────────┐                                                   │
│   │  Argo   │  Kubernetes原生的工作流引擎，负责调度执行          │
│   └─────────┘                                                   │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 1.2 为什么选择 dflow

| 传统方式 | dflow 方式 |
|---------|-----------|
| 代码耦合，难以复用 | OP 模块化，可组合复用 |
| 串行执行，效率低 | 自动识别依赖，最大化并行 |
| 失败后手动处理 | 自动重试，断点续跑 |
| 单机运行，资源受限 | K8s 调度，弹性扩展 |
| 日志分散，难以追踪 | 统一监控，可视化 DAG |

---

## 2. dflow 工作流设计思路

### 2.1 任务分解原则

将业务流程拆解为**独立、可复用、可测试**的原子操作：

```
业务需求：采集金融数据 → 存储 → AI分析 → 生成报告

拆解为 OP：
┌──────────────────────────────────────────────────────────────┐
│                                                              │
│  ┌─────────────┐   ┌─────────────┐   ┌─────────────┐        │
│  │ 采集OP      │   │ 存储OP      │   │ 分析OP      │        │
│  │             │   │             │   │             │        │
│  │ 输入:参数   │──▶│ 输入:文件   │──▶│ 输入:数据   │        │
│  │ 输出:文件   │   │ 输出:状态   │   │ 输出:报告   │        │
│  └─────────────┘   └─────────────┘   └─────────────┘        │
│                                                              │
└──────────────────────────────────────────────────────────────┘
```

**设计原则：**
1. **单一职责**：每个 OP 只做一件事
2. **无状态**：OP 不依赖外部状态，所有依赖通过输入传递
3. **幂等性**：相同输入产生相同输出，支持安全重试
4. **数据隔离**：OP 间通过 Artifact（文件）传递数据

### 2.2 并行化策略（v2.0 优化）

**v1.0 策略（已废弃）**：41 个 Slice 并行
- 问题：Pod 启动开销大，影响性能

**v2.0 策略（当前）**：2 个批量任务并行
- 个股采集：1 个 OP 批量采集 32 组数据
- 板块采集：1 个 OP 批量采集 9 组数据
- 优势：减少 Pod 开销，提升整体性能

```
v2.0 并行策略：

                    Workflow
                       │
         ┌─────────────┴─────────────┐
         │                           │
         ▼                           ▼
    ┌─────────────┐           ┌─────────────┐
    │ 批量采集    │           │ 批量采集    │
    │ 个股数据    │           │ 板块数据    │
    │ (32组合并)  │           │ (9组合并)   │
    └──────┬──────┘           └──────┬──────┘
           │                         │
           └────────────┬────────────┘
                        │
          ┌─────────────┼─────────────┐
          │             │             │
          ▼             ▼             ▼
    ┌──────────┐  ┌──────────┐  ┌──────────┐
    │ 存储个股  │  │ 存储板块  │  │ AI分析   │
    │  → MySQL │  │  → MySQL │  │→DeepSeek │
    └──────────┘  └──────────┘  └────┬─────┘
                                     │
                                     ▼
                               ┌──────────┐
                               │存储报告  │
                               │ → MinIO  │
                               └──────────┘
```

### 2.3 数据流设计

dflow 区分两种数据类型：

| 类型 | Parameter（参数） | Artifact（制品） |
|------|------------------|-----------------|
| 用途 | 小数据、配置项 | 大数据、文件 |
| 传递 | 直接传值 | 通过 S3/MinIO 存储 |
| 大小 | < 256KB | 无限制 |
| 示例 | market_choice=1 | data.json 文件 |

---

## 3. 本项目工作流架构（v2.0）

### 3.1 整体流程

```
┌─────────────────────────────────────────────────────────────────┐
│              完整流水线 (full) - v2.0 优化版                      │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Step 1: 并行采集（2 个任务）                                    │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │                                                         │    │
│  │   ┌───────────────────┐    ┌───────────────────┐       │    │
│  │   │ BatchCrawlStock   │    │ BatchCrawlSector  │       │    │
│  │   │ (32组数据合并)     │    │ (9组数据合并)      │       │    │
│  │   └─────────┬─────────┘    └─────────┬─────────┘       │    │
│  │             │                        │                  │    │
│  │             └────────────┬───────────┘                  │    │
│  │                          │                              │    │
│  └──────────────────────────┼──────────────────────────────┘    │
│                             │ 2个JSON文件                        │
│                             ▼                                    │
│  Step 2: 并行处理（两路）                                         │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │                                                         │    │
│  │   路线 A: 数据库存储                                     │    │
│  │   ┌───────────────────┐    ┌───────────────────┐       │    │
│  │   │ BatchStore        │    │ BatchStore        │       │    │
│  │   │ (个股→MySQL)      │    │ (板块→MySQL)      │       │    │
│  │   └───────────────────┘    └───────────────────┘       │    │
│  │                                                         │    │
│  │   路线 B: AI 分析                                        │    │
│  │   ┌───────────────────┐    ┌───────────────────┐       │    │
│  │   │ DeepSeekAnalysis  │───▶│ StoreToMinIO      │       │    │
│  │   │ (生成分析报告)     │    │ (报告存储)        │       │    │
│  │   └───────────────────┘    └───────────────────┘       │    │
│  │                                                         │    │
│  └─────────────────────────────────────────────────────────┘    │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 3.2 OP 职责划分（v2.0）

| OP | 职责 | 输入 | 输出 | 说明 |
|----|------|------|------|------|
| **BatchCrawlStockFlowOP** | 批量采集个股资金流 | 无 | JSON文件(32组) | 新增 |
| **BatchCrawlSectorFlowOP** | 批量采集板块资金流 | 无 | JSON文件(9组) | 新增 |
| **BatchStoreToMySQLOP** | 批量存储到MySQL | JSON文件 | 存储状态 | 新增 |
| **DeepSeekAnalysisOP** | AI智能分析 | 个股+板块文件 | 分析报告 | 新增 |
| **StoreReportToMinIOOP** | 存储报告到MinIO | 报告文件 | MinIO路径 | 新增 |
| ~~CrawlStockFlowOP~~ | 单任务采集 | - | - | 已废弃 |
| ~~StoreSingleFileOP~~ | 单文件存储 | - | - | 已废弃 |

### 3.3 工作流类型

| 工作流 | 命令 | 用途 | 包含步骤 |
|--------|------|------|----------|
| **full** | `run full` | 完整流程 | 采集+存储+AI分析+MinIO |
| **crawl** | `run crawl` | 只采集存储 | 采集+存储（无AI分析） |
| **incremental** | `run incremental` | 增量更新 | 部分市场采集 |
| **quick** | `run quick` | 快速刷新 | 最小采集 |

---

## 4. 环境配置

### 4.1 配置文件结构

```
项目根目录/
├── .env                    # 环境变量配置
└── backend/
    └── dflow_pipeline/
        └── config.py       # dflow 配置（自动加载 .env）
```

### 4.2 .env 文件配置

```bash
# =====================================================
# 金融智能数据采集与分析平台 - 环境变量配置
# =====================================================

# MySQL数据库配置（Pod 内部使用）
MYSQL_HOST=mysql
MYSQL_PORT=3306
MYSQL_USER=root
MYSQL_PASSWORD=your_password
MYSQL_DATABASE=financial_web_crawler

# MinIO对象存储配置（Pod 内部使用）
MINIO_ENDPOINT=minio:9000
MINIO_ACCESS_KEY=admin
MINIO_SECRET_KEY=admin123
MINIO_BUCKET=data-financial-agent

# Deepseek AI配置
DEEPSEEK_API_KEY=sk-xxxxx
DEEPSEEK_BASE_URL=https://api.deepseek.com
```

### 4.3 dflow 客户端配置

`config.py` 中有两套 MinIO 配置：

1. **dflow 客户端配置**（从本机提交到 K8s）
   ```python
   # 使用本地端口转发 (127.0.0.1:9000)
   s3_config["endpoint"] = "127.0.0.1:9000"
   s3_config["secret_key"] = "password"  # K8s my-minio-cred 密码
   ```

2. **Pod 内部配置**（从 .env 加载，传递给 Pod）
   ```python
   # 使用 K8s 内部 DNS (minio:9000)
   MINIO_ENDPOINT = "minio:9000"
   MINIO_SECRET_KEY = "admin123"  # .env 中的密码
   ```

---

## 5. 执行模型

### 5.1 dflow 执行流程

```
┌─────────────────────────────────────────────────────────────────┐
│                      dflow 执行流程                              │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  1. 定义阶段                                                     │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │  Python 代码定义 Workflow                                │    │
│  │  - 自动加载 .env 环境变量                                │    │
│  │  - 创建 OP Template                                      │    │
│  │  - 定义 Step 和依赖关系                                   │    │
│  └─────────────────────────────────────────────────────────┘    │
│                            │                                    │
│                            ▼                                    │
│  2. 提交阶段                                                     │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │  workflow.submit()                                       │    │
│  │  - 通过端口转发连接 Argo Server (127.0.0.1:2746)         │    │
│  │  - 上传 Python 包到 MinIO (127.0.0.1:9000)               │    │
│  │  - 返回 Workflow ID                                       │    │
│  └─────────────────────────────────────────────────────────┘    │
│                            │                                    │
│                            ▼                                    │
│  3. 执行阶段                                                     │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │  K8s Pod 执行                                            │    │
│  │  - 拉取容器镜像 (python:3.9-slim)                        │    │
│  │  - 执行 pre_script (pip install)                         │    │
│  │  - 下载输入 Artifact (从 MinIO minio:9000)               │    │
│  │  - 执行 OP.execute()                                     │    │
│  │  - 上传输出 Artifact                                     │    │
│  └─────────────────────────────────────────────────────────┘    │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 5.2 容器执行模型

每个 OP 在独立的容器中执行：

```
┌────────────────────────────────────────────────────────────┐
│                    K8s Pod                                 │
├────────────────────────────────────────────────────────────┤
│                                                            │
│  ┌──────────────┐    ┌──────────────┐    ┌──────────────┐  │
│  │ Init Container│    │ Main Container│    │ Wait Container│ │
│  │              │    │              │    │              │  │
│  │ 下载Artifact │───▶│ 执行OP代码  │───▶│ 上传Artifact │  │
│  │ 从 MinIO    │    │              │    │ 到 MinIO     │  │
│  └──────────────┘    └──────────────┘    └──────────────┘  │
│                                                            │
│  环境变量（从 full_pipeline.py 传入）:                       │
│  - MYSQL_HOST, MYSQL_PASSWORD, ...                         │
│  - DEEPSEEK_API_KEY, DEEPSEEK_BASE_URL                     │
│  - MINIO_ENDPOINT, MINIO_ACCESS_KEY, ...                   │
│                                                            │
└────────────────────────────────────────────────────────────┘
```

---

## 6. 使用指南

### 6.1 环境准备

```bash
# 1. 启动 minikube
minikube start

# 2. 确保服务正常运行
kubectl -n argo get pods

# 3. 启动端口转发（必须！）
kubectl -n argo port-forward svc/minio 9000:9000 --address 0.0.0.0 &
kubectl -n argo port-forward svc/argo-server 2746:2746 --address 0.0.0.0 &
```

### 6.2 运行工作流

```bash
cd /home/chy/dev/Financial_Program/backend

# 完整流水线（采集 + 存储 + AI 分析 + MinIO 报告）
PYTHONPATH=. python -m dflow_pipeline.run full

# 只采集和存储（不进行 AI 分析）
PYTHONPATH=. python -m dflow_pipeline.run crawl

# 增量更新
PYTHONPATH=. python -m dflow_pipeline.run incremental

# 快速刷新
PYTHONPATH=. python -m dflow_pipeline.run quick

# 本地调试模式（不需要 K8s）
PYTHONPATH=. python -m dflow_pipeline.run hello --debug
```

### 6.3 查看工作流状态

```bash
# 查看所有工作流
kubectl -n argo get workflows

# 查看工作流详情
kubectl -n argo describe workflow <workflow-name>

# 查看 Pod 日志
kubectl -n argo logs <pod-name> -c main

# Argo UI（浏览器）
# https://127.0.0.1:2746
```

---

## 7. 与现有系统的关系

### 7.1 双模式运行

重构后支持两种运行模式：

```
┌─────────────────────────────────────────────────────────────────┐
│                     运行模式选择                                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  模式A: Docker Compose（原有方式）                               │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │  适用场景：开发环境、单机部署                             │    │
│  │  调度方式：APScheduler                                    │    │
│  │  执行方式：串行                                           │    │
│  │  启动命令：docker compose up -d                           │    │
│  └─────────────────────────────────────────────────────────┘    │
│                                                                 │
│  模式B: dflow + K8s（新方式）                                    │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │  适用场景：生产环境、需要高可用                           │    │
│  │  调度方式：Argo CronWorkflow                              │    │
│  │  执行方式：并行                                           │    │
│  │  启动命令：python -m dflow_pipeline.run full              │    │
│  └─────────────────────────────────────────────────────────┘    │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 7.2 代码结构

```
backend/
├── crawler/              # 原有爬虫代码（保留）
├── ai/                   # 原有 AI 代码（保留）
└── dflow_pipeline/       # dflow 工作流（新增）
    ├── config.py         # 配置（自动加载 .env）
    ├── run.py            # 启动脚本
    ├── ops/              # OP 定义
    │   ├── batch_crawl_op.py       # 批量采集
    │   ├── batch_store_op.py       # 批量存储
    │   ├── deepseek_analysis_op.py # AI 分析
    │   └── minio_store_op.py       # MinIO 存储
    └── workflows/        # 工作流定义
        └── full_pipeline.py        # 完整流水线
```

---

## 8. 常见问题

### 8.1 MinIO 连接失败

```bash
# 检查端口转发
ss -tlnp | grep 9000

# 重新启动端口转发
kubectl -n argo port-forward svc/minio 9000:9000 --address 0.0.0.0 &
```

### 8.2 签名不匹配错误

K8s 中 MinIO 密码与 .env 不同：
- K8s my-minio-cred: `password`
- .env MINIO_SECRET_KEY: `admin123`

`config.py` 已配置使用 K8s 密码连接。

### 8.3 pip root 用户警告

已在所有 `pre_script` 中添加 `--root-user-action=ignore` 参数。

---

## 9. 总结

### 9.1 v2.0 优化点

| 优化项 | v1.0 | v2.0 |
|--------|------|------|
| 采集任务数 | 41 个 Slice | 2 个批量任务 |
| Pod 开销 | 高（41 个 Pod） | 低（2 个 Pod） |
| AI 分析 | 无 | DeepSeek 集成 |
| 报告存储 | 无 | MinIO 自动存储 |
| pip 警告 | 有 | 已修复 |
| 环境配置 | 手动 | 自动加载 .env |

### 9.2 核心价值

| 维度 | 价值 |
|------|------|
| **效率** | 批量采集，减少 Pod 启动开销 |
| **智能** | DeepSeek AI 自动分析金融数据 |
| **持久化** | 分析报告自动存储到 MinIO |
| **可观测** | Argo UI 可视化监控 |
| **配置化** | .env 自动加载，环境隔离 |

---

*dflow 重构指南 v4.0 - 2024-12*
