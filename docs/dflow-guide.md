# 金融数据采集平台 dflow 重构指南

## 1. 什么是 dflow

### 1.1 dflow 核心理念

**dflow** 是一个基于 Python 的科学计算工作流框架，其核心思想是：

> **将复杂任务拆解为可复用的原子操作（OP），通过 DAG（有向无环图）定义依赖关系，由调度引擎自动编排执行。**

```
┌─────────────────────────────────────────────────────────────────┐
│                        dflow 核心概念                            │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   ┌─────────┐                                                   │
│   │   OP    │  原子操作单元，定义输入→处理→输出                   │
│   └────┬────┘                                                   │
│        │                                                        │
│        ▼                                                        │
│   ┌─────────┐                                                   │
│   │  Step   │  OP的实例化，可配置参数、资源、重试策略             │
│   └────┬────┘                                                   │
│        │                                                        │
│        ▼                                                        │
│   ┌─────────┐                                                   │
│   │Workflow │  由多个Step组成的DAG，定义执行顺序和依赖           │
│   └────┬────┘                                                   │
│        │                                                        │
│        ▼                                                        │
│   ┌─────────┐                                                   │
│   │  Argo   │  Kubernetes原生的工作流引擎，负责调度执行          │
│   └─────────┘                                                   │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 1.2 为什么选择 dflow

| 传统方式 | dflow 方式 |
|---------|-----------|
| 代码耦合，难以复用 | OP 模块化，可组合复用 |
| 串行执行，效率低 | 自动识别依赖，最大化并行 |
| 失败后手动处理 | 自动重试，断点续跑 |
| 单机运行，资源受限 | K8s 调度，弹性扩展 |
| 日志分散，难以追踪 | 统一监控，可视化 DAG |

---

## 2. dflow 工作流设计思路

### 2.1 任务分解原则

将业务流程拆解为**独立、可复用、可测试**的原子操作：

```
业务需求：采集金融数据 → 存储 → AI分析 → 生成报告

拆解为 OP：
┌──────────────────────────────────────────────────────────────┐
│                                                              │
│  ┌─────────────┐   ┌─────────────┐   ┌─────────────┐        │
│  │ 采集OP      │   │ 存储OP      │   │ 分析OP      │        │
│  │             │   │             │   │             │        │
│  │ 输入:参数   │──▶│ 输入:文件   │──▶│ 输入:表名   │        │
│  │ 输出:文件   │   │ 输出:状态   │   │ 输出:结果   │        │
│  └─────────────┘   └─────────────┘   └─────────────┘        │
│                                                              │
└──────────────────────────────────────────────────────────────┘
```

**设计原则：**
1. **单一职责**：每个 OP 只做一件事
2. **无状态**：OP 不依赖外部状态，所有依赖通过输入传递
3. **幂等性**：相同输入产生相同输出，支持安全重试
4. **数据隔离**：OP 间通过 Artifact（文件）传递数据

### 2.2 并行化策略

dflow 通过 **Slices（切片）** 机制实现数据并行：

```
                    单任务
                       │
         ┌─────────────┼─────────────┐
         │             │             │
         ▼             ▼             ▼
    ┌─────────┐   ┌─────────┐   ┌─────────┐
    │ 参数1   │   │ 参数2   │   │ 参数3   │
    │ 切片执行 │   │ 切片执行 │   │ 切片执行 │
    └────┬────┘   └────┬────┘   └────┬────┘
         │             │             │
         └─────────────┼─────────────┘
                       │
                       ▼
                   结果汇聚
```

**本项目并行策略：**
- 个股采集：8 市场 × 4 周期 = **32 并行任务**
- 板块采集：3 板块 × 3 周期 = **9 并行任务**
- 总计：**41 个任务并行执行**

### 2.3 数据流设计

dflow 区分两种数据类型：

| 类型 | Parameter（参数） | Artifact（制品） |
|------|------------------|-----------------|
| 用途 | 小数据、配置项 | 大数据、文件 |
| 传递 | 直接传值 | 通过 S3/MinIO 存储 |
| 大小 | < 256KB | 无限制 |
| 示例 | market_choice=1 | data.json 文件 |

```
数据流设计：

┌──────────┐  Parameter   ┌──────────┐  Artifact   ┌──────────┐
│ 调用方   │─────────────▶│ 采集 OP  │────────────▶│ 存储 OP  │
│          │  market=1    │          │  data.json  │          │
│          │  day=1       │          │             │          │
└──────────┘              └──────────┘             └──────────┘
```

---

## 3. 本项目工作流架构

### 3.1 整体流程

```
┌─────────────────────────────────────────────────────────────────┐
│                     金融数据采集工作流                            │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  阶段1: 数据采集（并行）                                         │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │                                                         │    │
│  │   ┌───────┐ ┌───────┐ ┌───────┐       ┌───────┐        │    │
│  │   │Stock  │ │Stock  │ │Stock  │  ...  │Sector │        │    │
│  │   │M1-D1  │ │M1-D2  │ │M2-D1  │       │S3-D3  │        │    │
│  │   └───┬───┘ └───┬───┘ └───┬───┘       └───┬───┘        │    │
│  │       │         │         │               │            │    │
│  │       └─────────┴─────────┴───────────────┘            │    │
│  │                         │                              │    │
│  └─────────────────────────┼──────────────────────────────┘    │
│                            │ 41个JSON文件                       │
│                            ▼                                    │
│  阶段2: 数据存储（并行）                                         │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │                                                         │    │
│  │   ┌───────┐ ┌───────┐ ┌───────┐       ┌───────┐        │    │
│  │   │Store  │ │Store  │ │Store  │  ...  │Store  │        │    │
│  │   │Table1 │ │Table2 │ │Table3 │       │Table41│        │    │
│  │   └───┬───┘ └───┬───┘ └───┬───┘       └───┬───┘        │    │
│  │       │         │         │               │            │    │
│  │       └─────────┴─────────┴───────────────┘            │    │
│  │                         │                              │    │
│  └─────────────────────────┼──────────────────────────────┘    │
│                            │ 41张MySQL表                        │
│                            ▼                                    │
│  阶段3: AI分析（可选）                                           │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │                                                         │    │
│  │              ┌──────────────────────┐                   │    │
│  │              │    AI 分析 OP        │                   │    │
│  │              │  读取数据 → DeepSeek │                   │    │
│  │              └──────────┬───────────┘                   │    │
│  │                         │                               │    │
│  └─────────────────────────┼───────────────────────────────┘    │
│                            │ 分析结果                           │
│                            ▼                                    │
│  阶段4: 报告生成（可选）                                         │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │                                                         │    │
│  │              ┌──────────────────────┐                   │    │
│  │              │   报告生成 OP        │                   │    │
│  │              │  Markdown → MinIO    │                   │    │
│  │              └──────────────────────┘                   │    │
│  │                                                         │    │
│  └─────────────────────────────────────────────────────────┘    │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 3.2 OP 职责划分

| OP | 职责 | 输入 | 输出 | 并行度 |
|----|------|------|------|--------|
| **CrawlStockFlowOP** | 采集个股资金流 | 市场ID、周期 | JSON文件 | 32 |
| **CrawlSectorFlowOP** | 采集板块资金流 | 板块ID、周期 | JSON文件 | 9 |
| **StoreSingleFileOP** | 存储单个文件到MySQL | JSON文件 | 存储状态 | 41 |
| **AIAnalysisOP** | AI智能分析 | 表名、问题 | 分析结果 | 1 |
| **GenerateReportOP** | 生成分析报告 | 聊天历史 | 报告URL | 1 |

### 3.3 工作流类型

| 工作流 | 用途 | 任务数 | 耗时 | 调度频率 |
|--------|------|--------|------|----------|
| **full_pipeline** | 全量采集 | 41+41=82 | ~30秒 | 首次/手动 |
| **incremental** | 增量更新 | 11+11=22 | ~10秒 | 每5分钟 |
| **quick_refresh** | 快速刷新 | 1+1=2 | ~3秒 | 每1分钟 |

---

## 4. 执行模型

### 4.1 dflow 执行流程

```
┌─────────────────────────────────────────────────────────────────┐
│                      dflow 执行流程                              │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  1. 定义阶段                                                     │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │  Python 代码定义 Workflow                                │    │
│  │  - 创建 OP Template                                      │    │
│  │  - 定义 Step 和依赖关系                                   │    │
│  │  - 配置参数、资源、环境变量                               │    │
│  └─────────────────────────────────────────────────────────┘    │
│                            │                                    │
│                            ▼                                    │
│  2. 提交阶段                                                     │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │  workflow.submit()                                       │    │
│  │  - Python 代码转换为 Argo Workflow YAML                   │    │
│  │  - 上传到 Argo Server                                     │    │
│  │  - 返回 Workflow ID                                       │    │
│  └─────────────────────────────────────────────────────────┘    │
│                            │                                    │
│                            ▼                                    │
│  3. 调度阶段                                                     │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │  Argo Workflow Controller                                │    │
│  │  - 解析 DAG 依赖关系                                      │    │
│  │  - 调度可执行的 Step                                      │    │
│  │  - 为每个 Step 创建 K8s Pod                               │    │
│  └─────────────────────────────────────────────────────────┘    │
│                            │                                    │
│                            ▼                                    │
│  4. 执行阶段                                                     │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │  K8s Pod 执行                                            │    │
│  │  - 拉取容器镜像                                          │    │
│  │  - 下载输入 Artifact                                     │    │
│  │  - 执行 OP.execute()                                     │    │
│  │  - 上传输出 Artifact                                     │    │
│  └─────────────────────────────────────────────────────────┘    │
│                            │                                    │
│                            ▼                                    │
│  5. 完成阶段                                                     │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │  结果汇总                                                │    │
│  │  - 收集所有 Step 输出                                     │    │
│  │  - 更新 Workflow 状态                                     │    │
│  │  - 触发后续 Step 或标记完成                               │    │
│  └─────────────────────────────────────────────────────────┘    │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 4.2 容器执行模型

每个 OP 在独立的容器中执行：

```
┌────────────────────────────────────────────────────────────┐
│                    K8s Pod                                 │
├────────────────────────────────────────────────────────────┤
│                                                            │
│  ┌──────────────┐    ┌──────────────┐    ┌──────────────┐  │
│  │ Init Container│    │ Main Container│    │ Wait Container│ │
│  │              │    │              │    │              │  │
│  │ 下载Artifact │───▶│ 执行OP代码  │───▶│ 上传Artifact │  │
│  │ 从 MinIO    │    │              │    │ 到 MinIO     │  │
│  └──────────────┘    └──────────────┘    └──────────────┘  │
│                                                            │
│  共享存储卷: /tmp/artifacts                                 │
│                                                            │
└────────────────────────────────────────────────────────────┘
```

### 4.3 失败处理机制

```
任务执行
    │
    ▼
┌───────────┐
│ 执行成功？ │──是──▶ 继续下一步
└─────┬─────┘
      │否
      ▼
┌───────────┐
│ 重试次数  │──未达到──▶ 等待后重试
│ 已达上限？│
└─────┬─────┘
      │是
      ▼
┌───────────┐
│ 标记失败  │
│ 可手动重跑│
└───────────┘
```

---

## 5. 与现有系统的关系

### 5.1 双模式运行

重构后支持两种运行模式：

```
┌─────────────────────────────────────────────────────────────────┐
│                     运行模式选择                                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  模式A: Docker Compose（原有方式）                               │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │  适用场景：开发环境、单机部署                             │    │
│  │  调度方式：APScheduler                                    │    │
│  │  执行方式：串行                                           │    │
│  │  启动命令：docker compose up -d                           │    │
│  └─────────────────────────────────────────────────────────┘    │
│                                                                 │
│  模式B: dflow + K8s（新方式）                                    │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │  适用场景：生产环境、需要高可用                           │    │
│  │  调度方式：Argo CronWorkflow                              │    │
│  │  执行方式：并行                                           │    │
│  │  启动命令：python -m dflow_pipeline.run full              │    │
│  └─────────────────────────────────────────────────────────┘    │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 5.2 代码复用关系

```
┌─────────────────────────────────────────────────────────────────┐
│                      代码结构                                    │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  原有模块（保留）                dflow 模块（新增）               │
│  ┌────────────────────┐        ┌────────────────────┐          │
│  │ crawler/           │        │ dflow_pipeline/    │          │
│  │   crawler.py       │◀──复用──│   ops/             │          │
│  │                    │  核心   │     crawl_op.py   │          │
│  │                    │  逻辑   │     store_op.py   │          │
│  └────────────────────┘        └────────────────────┘          │
│                                                                 │
│  ┌────────────────────┐        ┌────────────────────┐          │
│  │ ai/                │        │ dflow_pipeline/    │          │
│  │   deepseek.py      │◀──复用──│   ops/             │          │
│  │   report.py        │  核心   │     ai_op.py      │          │
│  │                    │  逻辑   │     report_op.py  │          │
│  └────────────────────┘        └────────────────────┘          │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## 6. 实施路线图

### 6.1 分阶段实施

```
阶段1: 环境搭建（1天）
├── 安装 minikube
├── 部署 Argo Workflows
├── 配置 MinIO 存储
└── 验证环境可用

阶段2: OP 开发（2天）
├── 开发采集 OP
├── 开发存储 OP
├── 本地调试验证
└── 单元测试

阶段3: 工作流组装（1天）
├── 组装完整流水线
├── 组装增量更新流水线
├── 测试并行执行
└── 性能对比验证

阶段4: 生产部署（1天）
├── 配置 CronWorkflow
├── 监控告警配置
├── 文档完善
└── 逐步切换流量
```

### 6.2 回滚策略

如果 dflow 方案出现问题，可以立即回滚到原有方式：

1. 停止 CronWorkflow
2. 重启 Docker Compose 服务
3. APScheduler 自动恢复定时采集

---

## 7. 总结

### 7.1 核心价值

| 维度 | 价值 |
|------|------|
| **效率** | 采集时间从 5 分钟缩短到 30 秒 |
| **可靠性** | 自动重试、断点续跑、失败告警 |
| **可观测** | Argo UI 可视化监控、统一日志 |
| **扩展性** | K8s 弹性调度、支持更多数据源 |
| **复用性** | OP 模块化，可组合构建新流程 |

### 7.2 适用场景

✅ **推荐使用 dflow：**
- 生产环境需要高可用
- 数据量大，需要并行加速
- 需要复杂的任务编排
- 团队熟悉 K8s

❌ **不推荐使用 dflow：**
- 简单的单机开发环境
- 不熟悉 K8s 运维
- 任务简单，无需并行

---

*dflow 重构指南 v3.0*
